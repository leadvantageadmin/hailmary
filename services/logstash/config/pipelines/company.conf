# Company Table Pipeline Configuration
# Syncs Company table data to Elasticsearch

input {
  jdbc {
    # Database connection
    jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/postgresql-42.7.1.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://${POSTGRES_HOST:-hailmary-postgres}:${POSTGRES_PORT:-5432}/${POSTGRES_DB:-app}"
    jdbc_user => "${POSTGRES_USER:-app}"
    jdbc_password => "${POSTGRES_PASSWORD:-app}"
    
    # Query configuration
    statement => 'SELECT * FROM "Company" WHERE "updatedAt" > :sql_last_value ORDER BY "updatedAt"'
    use_column_value => true
    tracking_column => "updatedat"
    tracking_column_type => "timestamp"
    last_run_metadata_path => "/usr/share/logstash/data/checkpoints/company_last_run"
    
    # Scheduling - Using cron format for Logstash 7.x
    schedule => "*/30 * * * * *"
    
    # Connection settings
    jdbc_validate_connection => true
    jdbc_pool_timeout => 60
    
    # Cleanup
    clean_run => false
    record_last_run => true
  }
}

filter {
  # Add metadata
  mutate {
    add_field => { 
      "sync_source" => "company_table"
      "sync_timestamp" => "%{@timestamp}"
    }
  }
  
  # Convert timestamps
  date {
    match => [ "createdAt", "ISO8601" ]
    target => "createdAt"
  }
  
  date {
    match => [ "updatedAt", "ISO8601" ]
    target => "updatedAt"
  }
  
  # Transform data
  mutate {
    # Rename fields to match Elasticsearch mapping
    rename => { "domain" => "website" }
    
    # Convert numeric fields
    convert => { 
      "revenue" => "integer"
      "minEmployeeSize" => "integer"
      "maxEmployeeSize" => "integer"
    }
    
    # Add computed fields
    add_field => { 
      "size" => "%{minEmployeeSize}-%{maxEmployeeSize}"
    }
  }
  
  # Remove null values
  mutate {
    remove_field => [ "minEmployeeSize", "maxEmployeeSize" ]
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST:-hailmary-elasticsearch}:${ELASTICSEARCH_PORT:-9200}"]
    index => "company"
    document_id => "%{id}"
    
    # Authentication
    user => "${ELASTICSEARCH_USERNAME:-}"
    password => "${ELASTICSEARCH_PASSWORD:-}"
    
    # SSL settings
    ssl => "${ELASTICSEARCH_USE_SSL:-false}"
    ssl_certificate_verification => "${ELASTICSEARCH_VERIFY_CERTS:-false}"
    
    # Template settings
    template_name => "company"
    template => "/usr/share/logstash/config/templates/company.json"
    template_overwrite => true
  }
  
  # Debug output (remove in production)
  stdout {
    codec => rubydebug
  }
}
